[Input Output]
checkpoint_dir = ./training
deepspeech_graph_fname = ./ds_graph/deepspeech-0.5.0-models/output_graph.tflite
verts_mmaps_path = ./training_data/data_verts.npy
raw_audio_path = ./training_data/raw_audio_fixed.pkl
processed_audio_path = 
data2array_verts_path = ./training_data/subj_seq_to_idx.pkl

[Audio Parameters]
audio_feature_type = deepspeech
num_audio_features = 29
audio_window_size = 16
audio_window_stride = 1
condition_speech_features = False
speech_encoder_size_factor = 1.0

[Model Parameters]
num_vertices = 52
expression_dim = 50
init_expression = False
num_consecutive_frames = 2
absolute_reconstruction_loss = False
velocity_weight = 10.0
acceleration_weight = 0.0
verts_regularizer_weight = 0.0

[Data Setup]
subject_for_training = 1.mp4 2.mp4 3.mp4 4.mp4 5.mp4 6.mp4 

subject_for_validation = 7.mp4

[Learning Parameters]
batch_size = 64
learning_rate = 1e-4
decay_rate = 1.0
epoch_num = 30
adam_beta1_value = 0.9

[Visualization Parameters]
num_render_sequences = 3

